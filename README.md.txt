# ğŸ¯ Sentiment & Emotion Analysis Using NLP Techniques

This project applies **Natural Language Processing (NLP)** and **Machine Learning (ML)** techniques to classify text data
into emotions such as *happy* or *frustrated*.  
The workflow follows the **CRISPâ€“DM methodology**, demonstrating each phase â€” from business understanding to evaluation.

---

## ğŸ“˜ Project Overview

This notebook demonstrates an **end-to-end sentiment analysis pipeline**:
- Text preprocessing (tokenization, stopword removal, lemmatization)
- Feature extraction using **TF-IDF vectorization**
- Training and comparison of multiple ML models
- Evaluation and insights on model behavior and data quality

---

## ğŸ§© Objectives
- Understand and preprocess raw text data  
- Apply vectorization to convert text into numeric form  
- Train and evaluate several classification models  
- Analyze performance limitations on small/imbalanced datasets  

---

## ğŸ“Š Dataset
- **Total samples:** 25 (â‰ˆ30 KB)
- **Classes:** `happy`, `frustrated`
- **Features after TF-IDF:** 1 404
- **Train/Test split:** 80 % / 20 %

> âš ï¸ *This dataset is for demonstration only â€” it is too small for production-level modeling.*

---

## âš™ï¸ Methodology

| Phase | Description |
|:--|:--|
| **Business Understanding** | Define the goal â€” classify emotions in short text reviews. |
| **Data Understanding** | Explore the dataset, check class balance and sample distribution. |
| **Data Preparation** | Clean text, remove stopwords, tokenize & lemmatize, create TF-IDF features. |
| **Modeling** | Train models â€” Naive Bayes, Logistic Regression, KNN, Decision Tree, Random Forest. |
| **Evaluation** | Compare results using Accuracy, Precision, Recall, and F1-Score. |
| **Deployment** | Demonstrate prediction logic; ready for integration via Flask/FastAPI. |

---

## ğŸ§® Model Evaluation Results

| Metric | Training | Testing |
|:--|:--|:--|
| Accuracy | 0.80 | 0.40 |
| Precision | 0.84 | 0.16 |
| Recall | 0.80 | 0.40 |
| F1-Score | 0.80 | 0.23 |

**Confusion Matrix**

|            | Predicted Frustrated | Predicted Happy |
|-------------|----------------------|-----------------|
| **Actual Frustrated** | 0 | 3 |
| **Actual Happy** | 0 | 2 |

> The model tends to overpredict *happy* and fails to capture *frustrated* due to the small, imbalanced dataset.  
> Overfitting is visible: excellent training accuracy, poor test performance.

---

## ğŸ§  Insights & Observations
- **KNN**, **Decision Tree**, and **Random Forest** overfit heavily on the small dataset.  
- **Logistic Regression** provides a consistent baseline but still limited by data size.  
- **Hyperparameter tuning** did not improve results â€” lack of data is the main bottleneck.  
- The pipeline itself is **reproducible and educational** for NLP beginners.

---

## ğŸš€ Future Improvements
- Collect a **larger balanced dataset** (â‰¥ 1 000 samples)
- Apply **SMOTE** or other resampling for class balance
- Use **cross-validation**
- Experiment with **Word2Vec**, **LSTM**, or **BERT** embeddings
- Deploy model via **Flask** or **FastAPI** for live sentiment prediction

---

## ğŸ§° Tech Stack
- **Language:** Python 3  
- **Libraries:**  
  `pandas`, `numpy`, `nltk`, `scikit-learn`, `spacy`, `matplotlib`, `seaborn`, `wordcloud`, `PyPDF2`, `python-docx`

---

## ğŸ§¾ Project Structure

```
NLP_Sentiment_Analysis/
â”‚
â”œâ”€â”€ Data/ # Dataset and cleaned data
â”œâ”€â”€ Source_code/ # Jupyter notebook (Sentiment_Analysis.ipynb)
â”œâ”€â”€ Documentation/ #Report
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .gitignore # Ignore unnecessary files
â””â”€â”€ README.md # 
```

---

## âš™ï¸ Installation & Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/Hasnath-Unnisa/Sentiment_Analysis_with_NLP_Techniques.git
   cd Sentiment_Analysis_with_NLP_Techniques

2. Create virtual environment

python -m venv .venv
source .venv/Scripts/activate   # Windows

3.Install dependencies

pip install -r requirements.txt

4. Run the notebook

jupyter notebook Source_code/Sentiment_Analysis.ipynb

ğŸ Results Summary

Best Model: Logistic Regression

Accuracy: 40 %

Observation: Overfitting due to small dataset

Recommendation: Increase dataset size and test deep learning models

## ğŸ‘©â€ğŸ’» Author  

**Name:** Hasnath Unnisa  
**Email:** unnisahasnath@gmail.com  
**LinkedIn:** www.linkedin.com/in/hasnath22  
